{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa9af310",
   "metadata": {},
   "source": [
    "# Distributed PyTorch Operations with nbdistributed\n",
    "\n",
    "This notebook demonstrates distributed all_gather operations across multiple devices using nbdistributed package.\n",
    "\n",
    "## Setup Overview\n",
    "- **Coordinator (Mac)**: Runs this notebook and coordinates operations\n",
    "- **Worker (Windows RTX 2080)**: Provides GPU computation power\n",
    "\n",
    "## Requirements\n",
    "- Both machines must be on the same network\n",
    "- Windows machine should have CUDA-enabled PyTorch installed\n",
    "- nbdistributed package installed on both machines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf1894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install nbdistributed torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd4cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed imports and setup (removing problematic nbdistributed decorator)\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import os\n",
    "import socket\n",
    "import time\n",
    "\n",
    "# Check if CUDA is available on this machine (Mac)\n",
    "print(f\"CUDA available on Mac: {torch.cuda.is_available()}\")\n",
    "print(f\"Mac will run as CPU coordinator (Rank 0)\")\n",
    "\n",
    "# Check for Mac's Metal GPU support\n",
    "if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    print(\"Mac Metal Performance Shaders (MPS) available for local operations\")\n",
    "    mac_device = \"mps\"\n",
    "else:\n",
    "    print(\"Using CPU for Mac operations\")\n",
    "    mac_device = \"cpu\"\n",
    "\n",
    "print(f\"Mac device: {mac_device}\")\n",
    "\n",
    "# Get local IP address automatically from network interface\n",
    "def get_local_ip():\n",
    "    \"\"\"Get the actual local IP address (not localhost)\"\"\"\n",
    "    try:\n",
    "        # Connect to a remote address to determine which interface to use\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:\n",
    "            # Connect to Google DNS (doesn't actually send data)\n",
    "            s.connect((\"8.8.8.8\", 80))\n",
    "            local_ip = s.getsockname()[0]\n",
    "        return local_ip\n",
    "    except Exception:\n",
    "        # Fallback method\n",
    "        import subprocess\n",
    "        try:\n",
    "            # Get IP from ifconfig (macOS/Linux)\n",
    "            result = subprocess.run(['ifconfig'], capture_output=True, text=True)\n",
    "            for line in result.stdout.split('\\n'):\n",
    "                if 'inet ' in line and '127.0.0.1' not in line and 'inet 169.254' not in line:\n",
    "                    ip = line.split('inet ')[1].split(' ')[0]\n",
    "                    if ip.startswith('192.168.') or ip.startswith('10.') or ip.startswith('172.'):\n",
    "                        return ip\n",
    "        except:\n",
    "            pass\n",
    "        return \"192.168.1.1\"  # Last resort fallback\n",
    "\n",
    "local_ip = get_local_ip()\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "print(f\"üîç Auto-detected Mac IP (Master): {local_ip}\")\n",
    "print(f\"üì± Hostname: {hostname}\")\n",
    "print(f\"‚úÖ Using auto-detected IP address (not hostname)\")\n",
    "print(\"\\nSetup: Mac (CPU/MPS coordinator) + Windows (CUDA GPU worker)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e50c8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributed configuration\n",
    "MASTER_ADDR = local_ip  # This Mac will be the master\n",
    "MASTER_PORT = \"12355\"   # Port for communication\n",
    "WORLD_SIZE = 2          # Total number of processes (Mac + Windows)\n",
    "RANK = 0               # This machine's rank (master = 0)\n",
    "\n",
    "print(f\"Master Address (this Mac): {MASTER_ADDR}\")\n",
    "print(f\"Master Port: {MASTER_PORT}\")\n",
    "print(f\"World Size: {WORLD_SIZE}\")\n",
    "print(f\"This machine's rank: {RANK}\")\n",
    "\n",
    "# Set environment variables for distributed training\n",
    "os.environ['MASTER_ADDR'] = MASTER_ADDR\n",
    "os.environ['MASTER_PORT'] = MASTER_PORT\n",
    "os.environ['WORLD_SIZE'] = str(WORLD_SIZE)\n",
    "os.environ['RANK'] = str(RANK)\n",
    "\n",
    "print(f\"‚úÖ Mac configured as master node at {MASTER_ADDR}:{MASTER_PORT}\")\n",
    "print(f\"üîç Environment check:\")\n",
    "print(f\"   MASTER_ADDR = {os.environ.get('MASTER_ADDR')}\")\n",
    "print(f\"   MASTER_PORT = {os.environ.get('MASTER_PORT')}\")\n",
    "print(f\"‚ö†Ô∏è  MUST be IP address, NOT hostname!\")\n",
    "print(f\"‚ÑπÔ∏è  Waiting for Windows worker to connect...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7885a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFY IP-only setup (run this BEFORE starting Windows worker)\n",
    "def verify_ip_setup():\n",
    "    \"\"\"Verify that we're using IP addresses, not hostnames\"\"\"\n",
    "    print(\"üîç IP Setup Verification:\")\n",
    "    print(f\"‚úÖ Auto-detected IP: {local_ip}\")\n",
    "    print(f\"‚úÖ MASTER_ADDR will be: {local_ip}\")\n",
    "    \n",
    "    # Check that it's a valid IP format\n",
    "    import re\n",
    "    ip_pattern = r'^(\\d{1,3}\\.){3}\\d{1,3}$'\n",
    "    if re.match(ip_pattern, local_ip):\n",
    "        print(f\"‚úÖ Valid IP format: {local_ip}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Invalid IP format: {local_ip}\")\n",
    "        return False\n",
    "    \n",
    "    # Test if port is available\n",
    "    import socket\n",
    "    try:\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "            s.bind((local_ip, 12355))\n",
    "            print(f\"‚úÖ Port 12355 available on {local_ip}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Port 12355 not available: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run verification\n",
    "verify_ip_setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b5af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize distributed process group (run this after Windows worker is ready)\n",
    "def initialize_distributed():\n",
    "    \"\"\"Initialize the distributed environment with FORCED IP (no hostname)\"\"\"\n",
    "    try:\n",
    "        backend = 'gloo'\n",
    "        \n",
    "        # COMPLETELY CLEAR any hostname-related environment variables\n",
    "        hostname_vars = ['HOSTNAME', 'HOST', 'COMPUTERNAME']\n",
    "        for var in hostname_vars:\n",
    "            if var in os.environ:\n",
    "                del os.environ[var]\n",
    "        \n",
    "        # FORCE IP address - multiple methods to ensure no hostname resolution\n",
    "        os.environ['MASTER_ADDR'] = local_ip\n",
    "        os.environ['MASTER_PORT'] = '12355'\n",
    "        os.environ['WORLD_SIZE'] = '2'\n",
    "        os.environ['RANK'] = '0'\n",
    "        \n",
    "        # Clear any problematic gloo settings\n",
    "        gloo_vars = ['GLOO_SOCKET_IFNAME', 'NCCL_SOCKET_IFNAME', 'GLOO_DEVICE_TRANSPORT', 'GLOO_SOCKET_FAMILY']\n",
    "        for var in gloo_vars:\n",
    "            if var in os.environ:\n",
    "                del os.environ[var]\n",
    "        \n",
    "        print(f\"üîß FORCING IP-only connection:\")\n",
    "        print(f\"   MASTER_ADDR = {os.environ['MASTER_ADDR']}\")\n",
    "        print(f\"   NO hostname resolution allowed!\")\n",
    "        \n",
    "        print(f\"üîÑ Initializing distributed training with backend: {backend}\")\n",
    "        \n",
    "        # Method 1: Use environment variables only (more reliable on Mac)\n",
    "        print(f\"üîÑ Using environment variable method...\")\n",
    "        \n",
    "        dist.init_process_group(\n",
    "            backend=backend, \n",
    "            timeout=torch.distributed.default_pg_timeout\n",
    "        )\n",
    "        print(\"‚úÖ Environment method successful!\")\n",
    "        \n",
    "        rank = dist.get_rank()\n",
    "        world_size = dist.get_world_size()\n",
    "        \n",
    "        print(f\"‚úÖ Distributed initialized!\")\n",
    "        print(f\"Rank: {rank}, World size: {world_size}\")\n",
    "        print(\"üñ•Ô∏è  This is the Mac coordinator (Rank 0)\")\n",
    "        \n",
    "        return backend\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to initialize distributed: {e}\")\n",
    "        print(\"üîç Error details:\")\n",
    "        print(f\"   Exception type: {type(e).__name__}\")\n",
    "        print(f\"   Exception message: {str(e)}\")\n",
    "        print(\"\\nüí° Troubleshooting:\")\n",
    "        print(\"1. Ensure Windows worker is running first\")\n",
    "        print(\"2. Check that Windows worker connected to the correct IP\")\n",
    "        print(\"3. Verify firewall settings on both machines\")\n",
    "        return None\n",
    "\n",
    "# Don't run this yet - wait for Windows worker\n",
    "print(\"‚ö†Ô∏è  Ready to run coordinator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a90a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START MAC COORDINATOR - Run this to start listening for Windows worker\n",
    "print(\"üöÄ Starting Mac coordinator...\")\n",
    "backend = initialize_distributed()\n",
    "\n",
    "if backend:\n",
    "    print(\"üéâ SUCCESS! Mac coordinator is running!\")\n",
    "    print(\"‚úÖ Now start the Windows worker - it will connect automatically!\")\n",
    "    print(\"üß™ Ready for distributed operations!\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to start coordinator.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributed as dist\n",
    "from nbdistributed import make_distributed\n",
    "import os\n",
    "import socket\n",
    "\n",
    "# Check if CUDA is available on this machine (Mac)\n",
    "print(f\"CUDA available on Mac: {torch.cuda.is_available()}\")\n",
    "print(f\"Mac will run as CPU coordinator (Rank 0)\")\n",
    "\n",
    "# Check for Mac's Metal GPU support (optional)\n",
    "if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    print(\"Mac Metal Performance Shaders (MPS) available for local operations\")\n",
    "    mac_device = \"mps\"\n",
    "else:\n",
    "    print(\"Using CPU for Mac operations\")\n",
    "    mac_device = \"cpu\"\n",
    "\n",
    "print(f\"Mac device: {mac_device}\")\n",
    "\n",
    "# Get local IP address for network setup\n",
    "hostname = socket.gethostname()\n",
    "local_ip = socket.gethostbyname(hostname)\n",
    "print(f\"Mac IP (Master): {local_ip}\")\n",
    "print(f\"Hostname: {hostname}\")\n",
    "print(\"\\nSetup: Mac (CPU/MPS coordinator) + Windows (CUDA GPU worker)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edf2786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START MAC COORDINATOR - Run this to start listening for Windows worker\n",
    "print(\"üöÄ Starting Mac coordinator...\")\n",
    "backend = initialize_distributed()\n",
    "\n",
    "if backend:\n",
    "    print(\"üéâ SUCCESS! Mac coordinator is running!\")\n",
    "    print(\"‚úÖ Now start the Windows worker - it will connect automatically!\")\n",
    "    print(\"üß™ Ready for distributed operations!\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to start coordinator.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9fbae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test distributed all_gather operations\n",
    "def test_all_gather_basic():\n",
    "    \"\"\"Test basic all_gather operation across distributed nodes\"\"\"\n",
    "    if not dist.is_initialized():\n",
    "        print(\"‚ùå Distributed not initialized! Call initialize_distributed() first.\")\n",
    "        return None\n",
    "    \n",
    "    rank = dist.get_rank()\n",
    "    world_size = dist.get_world_size()\n",
    "    \n",
    "    # Device allocation based on rank and machine type\n",
    "    if rank == 0:\n",
    "        # Mac coordinator - use CPU or MPS if available\n",
    "        device = torch.device(mac_device)  # \"cpu\" or \"mps\"\n",
    "        print(f\"üñ•Ô∏è  Rank {rank} (Mac): Running on device {device}\")\n",
    "    else:\n",
    "        # Windows worker - should use CUDA\n",
    "        device = torch.device(\"cuda:0\")  # Windows RTX 2080\n",
    "        print(f\"üíª Rank {rank} (Windows): Running on device {device}\")\n",
    "    \n",
    "    # Create tensors with different data for each rank\n",
    "    tensor_list = [torch.zeros(3, dtype=torch.int64) for _ in range(world_size)]\n",
    "    \n",
    "    # Create input tensor with rank-specific data\n",
    "    input_tensor = torch.tensor([rank*100, rank*100+10, rank*100+20], dtype=torch.int64)\n",
    "    \n",
    "    # Move to appropriate device\n",
    "    if rank == 0:\n",
    "        input_tensor = input_tensor.to(device)\n",
    "        tensor_list = [t.to(device) for t in tensor_list]\n",
    "    \n",
    "    print(f\"Rank {rank}: Before all_gather - input: {input_tensor}\")\n",
    "    print(f\"Rank {rank}: Before all_gather - tensor_list: {tensor_list}\")\n",
    "    \n",
    "    # Perform all_gather\n",
    "    dist.all_gather(tensor_list, input_tensor)\n",
    "    \n",
    "    print(f\"Rank {rank}: After all_gather - tensor_list: {tensor_list}\")\n",
    "    \n",
    "    # Synchronize based on device type\n",
    "    if rank == 0 and mac_device == \"mps\":\n",
    "        torch.mps.synchronize()\n",
    "    elif rank != 0:  # Windows with CUDA\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    return tensor_list\n",
    "\n",
    "print(\"üß™ test_all_gather_basic() function ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77d8e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE INITIALIZATION - Run this cell after Windows worker is ready\n",
    "\n",
    "# Initialize distributed process group\n",
    "def initialize_distributed():\n",
    "    \"\"\"Initialize the distributed environment\"\"\"\n",
    "    try:\n",
    "        # Use 'gloo' backend for CPU-GPU mixed setup (Mac CPU + Windows GPU)\n",
    "        backend = 'gloo'\n",
    "        \n",
    "        print(f\"üîÑ Initializing distributed training with backend: {backend}\")\n",
    "        print(f\"Backend 'gloo' chosen for Mac (CPU/MPS) + Windows (GPU) setup\")\n",
    "        \n",
    "        # Initialize the process group\n",
    "        dist.init_process_group(backend=backend, timeout=torch.distributed.default_pg_timeout)\n",
    "        \n",
    "        rank = dist.get_rank()\n",
    "        world_size = dist.get_world_size()\n",
    "        \n",
    "        print(f\"‚úÖ Distributed initialized!\")\n",
    "        print(f\"Rank: {rank}, World size: {world_size}\")\n",
    "        \n",
    "        if rank == 0:\n",
    "            print(\"üñ•Ô∏è  This is the Mac coordinator (Rank 0)\")\n",
    "        else:\n",
    "            print(f\"üíª This is worker rank {rank}\")\n",
    "        \n",
    "        return backend\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to initialize distributed: {e}\")\n",
    "        print(\"Make sure Windows worker is running first!\")\n",
    "        return None\n",
    "\n",
    "# NOW: Initialize the distributed connection with Windows\n",
    "print(\"üöÄ Attempting to connect to Windows worker...\")\n",
    "backend = initialize_distributed()\n",
    "\n",
    "if backend:\n",
    "    print(\"üéâ SUCCESS! Connected to Windows worker!\")\n",
    "    print(\"üß™ Ready to run distributed operations!\")\n",
    "else:\n",
    "    print(\"‚ùå Connection failed. Check Windows worker status.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57387ec4",
   "metadata": {},
   "source": [
    "## Configure Distributed Setup\n",
    "\n",
    "**Step 1**: Note down your Mac's IP address from above. You'll need this for the Windows machine.\n",
    "\n",
    "**Step 2**: Configure the distributed environment. Update the `WINDOWS_IP` with your Windows laptop's IP address.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributed configuration\n",
    "MASTER_ADDR = local_ip  # This Mac will be the master\n",
    "MASTER_PORT = \"12355\"   # Port for communication\n",
    "WORLD_SIZE = 2          # Total number of processes (Mac + Windows)\n",
    "RANK = 0               # This machine's rank (master = 0)\n",
    "\n",
    "# TODO: Update this with your Windows laptop's IP\n",
    "WINDOWS_IP = \"192.168.1.XXX\"  # Replace with actual Windows IP\n",
    "\n",
    "print(f\"Master Address (this Mac): {MASTER_ADDR}\")\n",
    "print(f\"Master Port: {MASTER_PORT}\")\n",
    "print(f\"World Size: {WORLD_SIZE}\")\n",
    "print(f\"This machine's rank: {RANK}\")\n",
    "print(f\"Windows machine IP: {WINDOWS_IP}\")\n",
    "\n",
    "# Set environment variables for distributed training\n",
    "os.environ['MASTER_ADDR'] = MASTER_ADDR\n",
    "os.environ['MASTER_PORT'] = MASTER_PORT\n",
    "os.environ['WORLD_SIZE'] = str(WORLD_SIZE)\n",
    "os.environ['RANK'] = str(RANK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7719b0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize distributed process group\n",
    "@make_distributed\n",
    "def initialize_distributed():\n",
    "    \"\"\"Initialize the distributed environment\"\"\"\n",
    "    # Use 'gloo' backend for CPU-GPU mixed setup (Mac CPU + Windows GPU)\n",
    "    # 'gloo' supports heterogeneous setups better than 'nccl'\n",
    "    backend = 'gloo'\n",
    "    \n",
    "    print(f\"Initializing distributed training with backend: {backend}\")\n",
    "    print(f\"Backend 'gloo' chosen for Mac (CPU) + Windows (GPU) setup\")\n",
    "    print(f\"Rank: {dist.get_rank()}, World size: {dist.get_world_size()}\")\n",
    "    \n",
    "    rank = dist.get_rank()\n",
    "    if rank == 0:\n",
    "        print(\"This is the Mac coordinator (Rank 0)\")\n",
    "    else:\n",
    "        print(f\"This is worker rank {rank}\")\n",
    "    \n",
    "    return backend\n",
    "\n",
    "# This decorator will handle the distributed setup\n",
    "backend = initialize_distributed()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60595c8d",
   "metadata": {},
   "source": [
    "## All-Gather Operations Test\n",
    "\n",
    "Now let's implement the distributed all_gather operations similar to your original code, but adapted for distributed execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c54828",
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_distributed\n",
    "def test_all_gather_basic():\n",
    "    \"\"\"Test basic all_gather operation across distributed nodes\"\"\"\n",
    "    \n",
    "    rank = dist.get_rank()\n",
    "    world_size = dist.get_world_size()\n",
    "    \n",
    "    # Device allocation based on rank and machine type\n",
    "    if rank == 0:\n",
    "        # Mac coordinator - use CPU or MPS if available\n",
    "        device = torch.device(mac_device)  # \"cpu\" or \"mps\"\n",
    "        print(f\"Rank {rank} (Mac): Running on device {device}\")\n",
    "    else:\n",
    "        # Windows worker - should use CUDA\n",
    "        device = torch.device(f\"cuda:0\")  # Windows RTX 2080\n",
    "        print(f\"Rank {rank} (Windows): Running on device {device}\")\n",
    "    \n",
    "    # Create tensors with different data for each rank\n",
    "    tensor_list = [torch.zeros(3, dtype=torch.int64).to(device) for _ in range(world_size)]\n",
    "    \n",
    "    # Create input tensor with rank-specific data\n",
    "    input_tensor = torch.tensor([rank*100, rank*100+10, rank*100+20], dtype=torch.int64).to(device)\n",
    "    \n",
    "    print(f\"Rank {rank}: Before all_gather - input: {input_tensor}\")\n",
    "    print(f\"Rank {rank}: Before all_gather - tensor_list: {tensor_list}\")\n",
    "    \n",
    "    # Perform all_gather\n",
    "    dist.all_gather(tensor_list, input_tensor)\n",
    "    \n",
    "    print(f\"Rank {rank}: After all_gather - tensor_list: {tensor_list}\")\n",
    "    \n",
    "    # Synchronize based on device type\n",
    "    if rank == 0 and mac_device == \"mps\":\n",
    "        torch.mps.synchronize()\n",
    "    elif rank != 0:  # Windows with CUDA\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    return tensor_list\n",
    "\n",
    "# Run the basic all_gather test\n",
    "result = test_all_gather_basic()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7b15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_distributed  \n",
    "def test_all_gather_advanced():\n",
    "    \"\"\"Test more complex all_gather operations with timing\"\"\"\n",
    "    import time\n",
    "    \n",
    "    rank = dist.get_rank()\n",
    "    world_size = dist.get_world_size()\n",
    "    \n",
    "    # Device allocation based on rank and machine type\n",
    "    if rank == 0:\n",
    "        # Mac coordinator\n",
    "        device = torch.device(mac_device)\n",
    "        machine_type = \"Mac\"\n",
    "    else:\n",
    "        # Windows worker with RTX 2080\n",
    "        device = torch.device(f\"cuda:0\")\n",
    "        machine_type = \"Windows RTX 2080\"\n",
    "    \n",
    "    print(f\"\\n--- Advanced All-Gather Test ---\")\n",
    "    print(f\"Rank {rank} ({machine_type}): Running on device {device}\")\n",
    "    \n",
    "    # Test with larger tensors\n",
    "    tensor_size = (2, 3)  # 2x3 tensor\n",
    "    tensor_list = [torch.zeros(tensor_size, dtype=torch.int64).to(device) for _ in range(world_size)]\n",
    "    \n",
    "    # Create input tensor with more complex data\n",
    "    input_tensor = torch.tensor([[rank*10, rank*10+1, rank*10+2], \n",
    "                                [rank*10+3, rank*10+4, rank*10+5]], \n",
    "                               dtype=torch.int64).to(device)\n",
    "    \n",
    "    print(f\"Rank {rank}: Input tensor shape: {input_tensor.shape}\")\n",
    "    print(f\"Rank {rank}: Input tensor:\\n{input_tensor}\")\n",
    "    \n",
    "    # Time the operation\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Perform all_gather\n",
    "    dist.all_gather(tensor_list, input_tensor)\n",
    "    \n",
    "    # Synchronize based on device type\n",
    "    if rank == 0 and mac_device == \"mps\":\n",
    "        torch.mps.synchronize()\n",
    "    elif rank != 0:  # Windows with CUDA\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Rank {rank}: All-gather completed in {end_time - start_time:.4f} seconds\")\n",
    "    print(f\"Rank {rank}: Gathered tensors from all ranks:\")\n",
    "    for i, tensor in enumerate(tensor_list):\n",
    "        machine = \"Mac (CPU/MPS)\" if i == 0 else f\"Windows RTX 2080\"\n",
    "        print(f\"  From rank {i} ({machine}):\\n{tensor}\")\n",
    "    \n",
    "    return tensor_list, end_time - start_time\n",
    "\n",
    "# Run the advanced all_gather test\n",
    "result_advanced, timing = test_all_gather_advanced()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11b4b18",
   "metadata": {},
   "source": [
    "## Windows RTX 2080 Setup Instructions\n",
    "\n",
    "**On your Windows laptop with RTX 2080, create this Python script (`worker.py`):**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import os\n",
    "\n",
    "# Configuration - UPDATE THESE VALUES\n",
    "MASTER_ADDR = \"YOUR_MAC_IP_HERE\"  # Replace with your Mac's IP from above\n",
    "MASTER_PORT = \"12355\"\n",
    "WORLD_SIZE = 2\n",
    "RANK = 1  # Windows machine is rank 1\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['MASTER_ADDR'] = MASTER_ADDR\n",
    "os.environ['MASTER_PORT'] = MASTER_PORT\n",
    "os.environ['WORLD_SIZE'] = str(WORLD_SIZE)\n",
    "os.environ['RANK'] = str(RANK)\n",
    "\n",
    "# Initialize distributed process group\n",
    "dist.init_process_group(backend='gloo')\n",
    "\n",
    "print(f\"Windows worker initialized with CUDA: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Rank: {dist.get_rank()}, World size: {dist.get_world_size()}\")\n",
    "\n",
    "# Keep the worker running and ready for operations\n",
    "try:\n",
    "    print(\"Windows worker ready for distributed operations...\")\n",
    "    # This will keep the process alive for distributed operations\n",
    "    dist.barrier()  # Wait for coordination\n",
    "    print(\"Distributed operations completed!\")\n",
    "finally:\n",
    "    dist.destroy_process_group()\n",
    "```\n",
    "\n",
    "**Steps to run:**\n",
    "1. Install PyTorch with CUDA support on Windows: `pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118`\n",
    "2. Update `MASTER_ADDR` in the script with your Mac's IP\n",
    "3. Run: `python worker.py`\n",
    "4. Then run the cells in this notebook on your Mac\n",
    "\n",
    "**Network requirements:**\n",
    "- Both machines on same network\n",
    "- Port 12355 open for communication\n",
    "- Firewall may need configuration\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
