{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa9af310",
   "metadata": {},
   "source": [
    "# Distributed PyTorch Operations with nbdistributed\n",
    "\n",
    "This notebook demonstrates distributed all_gather operations across multiple devices using nbdistributed package.\n",
    "\n",
    "## Setup Overview\n",
    "- **Coordinator (Mac)**: Runs this notebook and coordinates operations\n",
    "- **Worker (Windows RTX 2080)**: Provides GPU computation power\n",
    "\n",
    "## Requirements\n",
    "- Both machines must be on the same network\n",
    "- Windows machine should have CUDA-enabled PyTorch installed\n",
    "- nbdistributed package installed on both machines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf1894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install nbdistributed torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributed as dist\n",
    "from nbdistributed import make_distributed\n",
    "import os\n",
    "import socket\n",
    "\n",
    "# Check if CUDA is available on this machine (Mac)\n",
    "print(f\"CUDA available on Mac: {torch.cuda.is_available()}\")\n",
    "print(f\"Mac will run as CPU coordinator (Rank 0)\")\n",
    "\n",
    "# Check for Mac's Metal GPU support (optional)\n",
    "if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    print(\"Mac Metal Performance Shaders (MPS) available for local operations\")\n",
    "    mac_device = \"mps\"\n",
    "else:\n",
    "    print(\"Using CPU for Mac operations\")\n",
    "    mac_device = \"cpu\"\n",
    "\n",
    "print(f\"Mac device: {mac_device}\")\n",
    "\n",
    "# Get local IP address for network setup\n",
    "hostname = socket.gethostname()\n",
    "local_ip = socket.gethostbyname(hostname)\n",
    "print(f\"Mac IP (Master): {local_ip}\")\n",
    "print(f\"Hostname: {hostname}\")\n",
    "print(\"\\nSetup: Mac (CPU/MPS coordinator) + Windows (CUDA GPU worker)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57387ec4",
   "metadata": {},
   "source": [
    "## Configure Distributed Setup\n",
    "\n",
    "**Step 1**: Note down your Mac's IP address from above. You'll need this for the Windows machine.\n",
    "\n",
    "**Step 2**: Configure the distributed environment. Update the `WINDOWS_IP` with your Windows laptop's IP address.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributed configuration\n",
    "MASTER_ADDR = local_ip  # This Mac will be the master\n",
    "MASTER_PORT = \"12355\"   # Port for communication\n",
    "WORLD_SIZE = 2          # Total number of processes (Mac + Windows)\n",
    "RANK = 0               # This machine's rank (master = 0)\n",
    "\n",
    "# TODO: Update this with your Windows laptop's IP\n",
    "WINDOWS_IP = \"192.168.1.XXX\"  # Replace with actual Windows IP\n",
    "\n",
    "print(f\"Master Address (this Mac): {MASTER_ADDR}\")\n",
    "print(f\"Master Port: {MASTER_PORT}\")\n",
    "print(f\"World Size: {WORLD_SIZE}\")\n",
    "print(f\"This machine's rank: {RANK}\")\n",
    "print(f\"Windows machine IP: {WINDOWS_IP}\")\n",
    "\n",
    "# Set environment variables for distributed training\n",
    "os.environ['MASTER_ADDR'] = MASTER_ADDR\n",
    "os.environ['MASTER_PORT'] = MASTER_PORT\n",
    "os.environ['WORLD_SIZE'] = str(WORLD_SIZE)\n",
    "os.environ['RANK'] = str(RANK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7719b0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize distributed process group\n",
    "@make_distributed\n",
    "def initialize_distributed():\n",
    "    \"\"\"Initialize the distributed environment\"\"\"\n",
    "    # Use 'gloo' backend for CPU-GPU mixed setup (Mac CPU + Windows GPU)\n",
    "    # 'gloo' supports heterogeneous setups better than 'nccl'\n",
    "    backend = 'gloo'\n",
    "    \n",
    "    print(f\"Initializing distributed training with backend: {backend}\")\n",
    "    print(f\"Backend 'gloo' chosen for Mac (CPU) + Windows (GPU) setup\")\n",
    "    print(f\"Rank: {dist.get_rank()}, World size: {dist.get_world_size()}\")\n",
    "    \n",
    "    rank = dist.get_rank()\n",
    "    if rank == 0:\n",
    "        print(\"This is the Mac coordinator (Rank 0)\")\n",
    "    else:\n",
    "        print(f\"This is worker rank {rank}\")\n",
    "    \n",
    "    return backend\n",
    "\n",
    "# This decorator will handle the distributed setup\n",
    "backend = initialize_distributed()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60595c8d",
   "metadata": {},
   "source": [
    "## All-Gather Operations Test\n",
    "\n",
    "Now let's implement the distributed all_gather operations similar to your original code, but adapted for distributed execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c54828",
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_distributed\n",
    "def test_all_gather_basic():\n",
    "    \"\"\"Test basic all_gather operation across distributed nodes\"\"\"\n",
    "    \n",
    "    rank = dist.get_rank()\n",
    "    world_size = dist.get_world_size()\n",
    "    \n",
    "    # Device allocation based on rank and machine type\n",
    "    if rank == 0:\n",
    "        # Mac coordinator - use CPU or MPS if available\n",
    "        device = torch.device(mac_device)  # \"cpu\" or \"mps\"\n",
    "        print(f\"Rank {rank} (Mac): Running on device {device}\")\n",
    "    else:\n",
    "        # Windows worker - should use CUDA\n",
    "        device = torch.device(f\"cuda:0\")  # Windows RTX 2080\n",
    "        print(f\"Rank {rank} (Windows): Running on device {device}\")\n",
    "    \n",
    "    # Create tensors with different data for each rank\n",
    "    tensor_list = [torch.zeros(3, dtype=torch.int64).to(device) for _ in range(world_size)]\n",
    "    \n",
    "    # Create input tensor with rank-specific data\n",
    "    input_tensor = torch.tensor([rank*100, rank*100+10, rank*100+20], dtype=torch.int64).to(device)\n",
    "    \n",
    "    print(f\"Rank {rank}: Before all_gather - input: {input_tensor}\")\n",
    "    print(f\"Rank {rank}: Before all_gather - tensor_list: {tensor_list}\")\n",
    "    \n",
    "    # Perform all_gather\n",
    "    dist.all_gather(tensor_list, input_tensor)\n",
    "    \n",
    "    print(f\"Rank {rank}: After all_gather - tensor_list: {tensor_list}\")\n",
    "    \n",
    "    # Synchronize based on device type\n",
    "    if rank == 0 and mac_device == \"mps\":\n",
    "        torch.mps.synchronize()\n",
    "    elif rank != 0:  # Windows with CUDA\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    return tensor_list\n",
    "\n",
    "# Run the basic all_gather test\n",
    "result = test_all_gather_basic()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7b15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_distributed  \n",
    "def test_all_gather_advanced():\n",
    "    \"\"\"Test more complex all_gather operations with timing\"\"\"\n",
    "    import time\n",
    "    \n",
    "    rank = dist.get_rank()\n",
    "    world_size = dist.get_world_size()\n",
    "    \n",
    "    # Device allocation based on rank and machine type\n",
    "    if rank == 0:\n",
    "        # Mac coordinator\n",
    "        device = torch.device(mac_device)\n",
    "        machine_type = \"Mac\"\n",
    "    else:\n",
    "        # Windows worker with RTX 2080\n",
    "        device = torch.device(f\"cuda:0\")\n",
    "        machine_type = \"Windows RTX 2080\"\n",
    "    \n",
    "    print(f\"\\n--- Advanced All-Gather Test ---\")\n",
    "    print(f\"Rank {rank} ({machine_type}): Running on device {device}\")\n",
    "    \n",
    "    # Test with larger tensors\n",
    "    tensor_size = (2, 3)  # 2x3 tensor\n",
    "    tensor_list = [torch.zeros(tensor_size, dtype=torch.int64).to(device) for _ in range(world_size)]\n",
    "    \n",
    "    # Create input tensor with more complex data\n",
    "    input_tensor = torch.tensor([[rank*10, rank*10+1, rank*10+2], \n",
    "                                [rank*10+3, rank*10+4, rank*10+5]], \n",
    "                               dtype=torch.int64).to(device)\n",
    "    \n",
    "    print(f\"Rank {rank}: Input tensor shape: {input_tensor.shape}\")\n",
    "    print(f\"Rank {rank}: Input tensor:\\n{input_tensor}\")\n",
    "    \n",
    "    # Time the operation\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Perform all_gather\n",
    "    dist.all_gather(tensor_list, input_tensor)\n",
    "    \n",
    "    # Synchronize based on device type\n",
    "    if rank == 0 and mac_device == \"mps\":\n",
    "        torch.mps.synchronize()\n",
    "    elif rank != 0:  # Windows with CUDA\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Rank {rank}: All-gather completed in {end_time - start_time:.4f} seconds\")\n",
    "    print(f\"Rank {rank}: Gathered tensors from all ranks:\")\n",
    "    for i, tensor in enumerate(tensor_list):\n",
    "        machine = \"Mac (CPU/MPS)\" if i == 0 else f\"Windows RTX 2080\"\n",
    "        print(f\"  From rank {i} ({machine}):\\n{tensor}\")\n",
    "    \n",
    "    return tensor_list, end_time - start_time\n",
    "\n",
    "# Run the advanced all_gather test\n",
    "result_advanced, timing = test_all_gather_advanced()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11b4b18",
   "metadata": {},
   "source": [
    "## Windows RTX 2080 Setup Instructions\n",
    "\n",
    "**On your Windows laptop with RTX 2080, create this Python script (`worker.py`):**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import os\n",
    "\n",
    "# Configuration - UPDATE THESE VALUES\n",
    "MASTER_ADDR = \"YOUR_MAC_IP_HERE\"  # Replace with your Mac's IP from above\n",
    "MASTER_PORT = \"12355\"\n",
    "WORLD_SIZE = 2\n",
    "RANK = 1  # Windows machine is rank 1\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['MASTER_ADDR'] = MASTER_ADDR\n",
    "os.environ['MASTER_PORT'] = MASTER_PORT\n",
    "os.environ['WORLD_SIZE'] = str(WORLD_SIZE)\n",
    "os.environ['RANK'] = str(RANK)\n",
    "\n",
    "# Initialize distributed process group\n",
    "dist.init_process_group(backend='gloo')\n",
    "\n",
    "print(f\"Windows worker initialized with CUDA: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Rank: {dist.get_rank()}, World size: {dist.get_world_size()}\")\n",
    "\n",
    "# Keep the worker running and ready for operations\n",
    "try:\n",
    "    print(\"Windows worker ready for distributed operations...\")\n",
    "    # This will keep the process alive for distributed operations\n",
    "    dist.barrier()  # Wait for coordination\n",
    "    print(\"Distributed operations completed!\")\n",
    "finally:\n",
    "    dist.destroy_process_group()\n",
    "```\n",
    "\n",
    "**Steps to run:**\n",
    "1. Install PyTorch with CUDA support on Windows: `pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118`\n",
    "2. Update `MASTER_ADDR` in the script with your Mac's IP\n",
    "3. Run: `python worker.py`\n",
    "4. Then run the cells in this notebook on your Mac\n",
    "\n",
    "**Network requirements:**\n",
    "- Both machines on same network\n",
    "- Port 12355 open for communication\n",
    "- Firewall may need configuration\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
